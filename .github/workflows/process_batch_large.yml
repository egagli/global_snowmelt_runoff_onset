name: Process Batch Large (>256 tiles)

on:
  workflow_dispatch:
    inputs:
      which_tiles_to_process:
        description: 'Which tiles to process'
        required: false
        default: 'unprocessed'
        type: choice
        options:
        - all
        - processed
        - failed
        - unprocessed
        - unprocessed_and_failed
        - unprocessed_and_failed_weather_stations
      how_many:
        description: 'How many tiles to process (use Small Batch for â‰¤256)'
        required: false
        default: '1000'
        type: string
      config_file:
        description: 'Config file to use (e.g., global_config_v9.txt)'
        required: false
        default: 'global_config_v9.txt'
        type: string
      max_parallel:
        description: 'Maximum number of parallel jobs'
        required: false
        default: '5'
        type: string

env:
  AZURE_STORAGE_SAS_TOKEN: ${{ secrets.AZURE_STORAGE_SAS_TOKEN }}
  AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}

permissions:
  contents: write

jobs:
  generate-tile-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.get-tiles.outputs.matrix }}
      tile-count: ${{ steps.get-tiles.outputs.count }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Miniforge
      uses: conda-incubator/setup-miniconda@v3
      with:
        miniforge-version: latest
        miniforge-variant: Miniforge3
        channels: conda-forge,defaults
        channel-priority: true
        activate-environment: global_snowmelt_runoff_onset_actions
        environment-file: environment_github_actions.yml
        
    - name: Install package
      shell: bash -l {0}
      run: |
        pip install -e .
        
    - name: Get tiles for batch processing
      id: get-tiles
      shell: bash -l {0}
      run: |
        COUNT=$(python processing/scripts/get_tiles_for_batch.py \
          --config-file ${{ github.event.inputs.config_file }} \
          --which-tiles ${{ github.event.inputs.which_tiles_to_process }} \
          --how-many ${{ github.event.inputs.how_many }} \
          --batch-index -1 \
          --output count)
        echo "count=$COUNT" >> $GITHUB_OUTPUT
        
        # Provide information about the processing approach
        if [ $COUNT -le 256 ]; then
          echo "â„¹ï¸  Processing $COUNT tiles - consider using 'Process Tile Small Batch' for faster processing"
        else
          echo "ðŸš€ Processing $COUNT tiles using large batch workflow"
          echo "ðŸ“Š This will use multiple parallel matrix jobs to handle the scale"
        fi
        
        MATRIX=$(python processing/scripts/get_tiles_for_batch.py \
          --config-file ${{ github.event.inputs.config_file }} \
          --which-tiles ${{ github.event.inputs.which_tiles_to_process }} \
          --how-many ${{ github.event.inputs.how_many }} \
          --batch-index -1 \
          --output json)
        echo "matrix=$MATRIX" >> $GITHUB_OUTPUT

  process-tiles:
    needs: generate-tile-matrix
    if: fromJson(needs.generate-tile-matrix.outputs.tile-count) > 0
    runs-on: ubuntu-latest
    timeout-minutes: 120
    strategy:
      max-parallel: ${{ fromJson(github.event.inputs.max_parallel) }}
      fail-fast: false
      matrix:
        tile: ${{ fromJson(needs.generate-tile-matrix.outputs.matrix) }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Miniforge
      uses: conda-incubator/setup-miniconda@v3
      with:
        miniforge-version: latest
        miniforge-variant: Miniforge3
        channels: conda-forge,defaults
        channel-priority: true
        activate-environment: global_snowmelt_runoff_onset_actions
        environment-file: environment_github_actions.yml
        
    - name: Install package
      shell: bash -l {0}
      run: |
        pip install -e .
        
    - name: Process tile
      shell: bash -l {0}
      run: |
        python processing/scripts/process_single_tile.py \
          --tile-row ${{ matrix.tile.row }} \
          --tile-col ${{ matrix.tile.col }} \
          --config-file ${{ github.event.inputs.config_file }}
          
    - name: Create failure record if processing crashed
      if: always()
      shell: bash -l {0}
      run: |
        CONFIG_FILE="${{ github.event.inputs.config_file }}"
        VERSION=$(echo "$CONFIG_FILE" | sed 's/.*v\([0-9]*\).*/v\1/')
        
        # Check if processing succeeded by looking at the main CSV
        python -c "
        import pandas as pd
        from pathlib import Path
        import sys
        
        version = '${VERSION}'
        main_csv = Path(f'processing/tile_data/tile_results_{version}.csv')
        
        if main_csv.exists():
            try:
                df = pd.read_csv(main_csv)
                # Check if our tile exists and succeeded
                tile_rows = df[(df['row'] == ${{ matrix.tile.row }}) & 
                              (df['col'] == ${{ matrix.tile.col }})]
                
                if len(tile_rows) > 0 and tile_rows.iloc[-1]['success']:
                    print('Tile processing succeeded')
                    sys.exit(0)
            except Exception as e:
                print(f'Error checking main CSV: {e}')
        
        # If we get here, processing failed - add failure record
        print('Adding failure record to main CSV')
        
        failure_data = {
            'row': [${{ matrix.tile.row }}],
            'col': [${{ matrix.tile.col }}],
            'success': [False],
            'total_time': [0],
            'error_messages': ['Batch workflow crashed - processing failed'],
            'tr_2015': [None], 'tr_2016': [None], 'tr_2017': [None], 'tr_2018': [None], 'tr_2019': [None],
            'tr_2020': [None], 'tr_2021': [None], 'tr_2022': [None], 'tr_2023': [None], 'tr_2024': [None],
            'pix_ct_2015': [None], 'pix_ct_2016': [None], 'pix_ct_2017': [None], 'pix_ct_2018': [None], 'pix_ct_2019': [None],
            'pix_ct_2020': [None], 'pix_ct_2021': [None], 'pix_ct_2022': [None], 'pix_ct_2023': [None], 'pix_ct_2024': [None]
        }
        
        failure_df = pd.DataFrame(failure_data)
        
        # Append to main CSV
        if main_csv.exists():
            failure_df.to_csv(main_csv, mode='a', header=False, index=False)
        else:
            failure_df.to_csv(main_csv, index=False)
        
        print(f'Added failure record to {main_csv}')
        "
        
    - name: Commit batch tile results
      if: always()
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action (Batch)"
        
        # Only commit changes to main CSV files
        if [[ -n "$(git status --porcelain processing/tile_data/tile_results_*.csv)" ]]; then
          git add processing/tile_data/tile_results_*.csv
          
          for i in {1..5}; do
            git pull origin main --no-rebase || echo "Pull failed, continuing..."
            
            if ! git diff --staged --quiet; then
              git commit -m "Add batch tile (${{ matrix.tile.row }}, ${{ matrix.tile.col }}) results" || echo "Commit failed, may already be committed"
            fi
            
            if git push; then
              echo "Successfully pushed batch tile results"
              break
            else
              echo "Push failed (attempt $i/5), waiting before retry..."
              sleep $((i * 2))
              git add processing/tile_data/tile_results_*.csv
            fi
            
            if [ $i -eq 5 ]; then
              echo "Failed to push after 5 attempts"
              exit 1
            fi
          done
        else
          echo "No changes to main CSV files"
        fi
        
    - name: Commit tile results
      if: always()
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action (Batch)"
        
        if [[ -n "$(git status --porcelain processing/tile_data/)" ]]; then
          git add processing/tile_data/
          
          for i in {1..5}; do
            git pull origin main --no-rebase || echo "Pull failed, continuing..."
            
            if ! git diff --staged --quiet; then
              git commit -m "Add batch tile (${{ matrix.tile.row }}, ${{ matrix.tile.col }}) results" || echo "Commit failed, may already be committed"
            fi
            
            if git push; then
              echo "Successfully pushed tile results"
              break
            else
              echo "Push failed (attempt $i/5), waiting before retry..."
              sleep $((i * 2))
              git add processing/tile_data/
            fi
            
            if [ $i -eq 5 ]; then
              echo "Failed to push after 5 attempts"
              exit 1
            fi
          done
        else
          echo "No changes to commit"
        fi
