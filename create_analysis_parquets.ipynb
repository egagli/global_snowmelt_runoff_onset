{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create parquet files for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xdem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/.local/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/home/eric/.local/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"d27f2e6b-22d9-4f12-97c9-fb89a71bc06f\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"39da65a3-b1ea-46a4-811c-4639883efd2e\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"e7e5028652634f038b2083508a9c5858\",\"client_comm_id\":\"1f1aa285c4ce4a75b8f580762dc9b2bd\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"39da65a3-b1ea-46a4-811c-4639883efd2e\",\"roots\":{\"p1002\":\"d27f2e6b-22d9-4f12-97c9-fb89a71bc06f\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import easysnowdata\n",
    "import pystac_client\n",
    "from sys import getsizeof\n",
    "import tqdm\n",
    "import planetary_computer\n",
    "import adlfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import odc.stac\n",
    "import pathlib\n",
    "import configparser\n",
    "import shapely\n",
    "import time\n",
    "import gc\n",
    "import dask\n",
    "import dask.distributed\n",
    "import coiled\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import traceback\n",
    "import xdem\n",
    "import rasterio\n",
    "import hvplot.xarray\n",
    "import seaborn as sns\n",
    "import atexit\n",
    "import dask.dataframe as dd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_token = pathlib.Path('sas_token.txt').read_text()\n",
    "\n",
    "valid_tiles_gdf = gpd.read_file('valid_tiles.geojson')\n",
    "valid_tiles_gdf = valid_tiles_gdf.sort_values(by='percent_valid_snow_pixels',ascending=False) \n",
    "#valid_tiles_gdf.explore(column='percent_valid_snow_pixels')\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read('global_config.txt')\n",
    "resolution = config.getfloat('VALUES', 'resolution')\n",
    "zarr_chunk_size = (config.getint('VALUES', 'chunk_size'),config.getint('VALUES', 'chunk_size'))\n",
    "bbox_left = config.getfloat('VALUES', 'bbox_left')\n",
    "bbox_right = config.getfloat('VALUES', 'bbox_right')\n",
    "bbox_top = config.getfloat('VALUES', 'bbox_top')\n",
    "bbox_bottom = config.getfloat('VALUES', 'bbox_bottom')\n",
    "\n",
    "WY_start = config.getint('VALUES', 'WY_start') \n",
    "WY_end = config.getint('VALUES', 'WY_end') \n",
    "water_years = np.arange(WY_start, WY_end + 1)\n",
    "\n",
    "min_years_for_median_std = config.getint('VALUES', 'min_years_for_median_std')\n",
    "\n",
    "min_monthly_acquisitions = config.getint('VALUES', 'min_monthly_acquisitions')\n",
    "max_allowed_days_gap_per_orbit = config.getint('VALUES', 'max_allowed_days_gap_per_orbit')\n",
    "low_backscatter_threshold = config.getfloat('VALUES', 'low_backscatter_threshold')\n",
    "\n",
    "start_date = '2014-01-01'\n",
    "today = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "end_date = today\n",
    "\n",
    "print(f'Config loaded: \\n{resolution=}, \\n{zarr_chunk_size=}, \\n{bbox_left=}, \\n{bbox_right=}, \\n{bbox_top=}, \\n{bbox_bottom=}, \\n{start_date=}, \\n{end_date=} \\n{water_years=}, \\n{min_years_for_median_std=}, \\n{low_backscatter_threshold=}, \\n{min_monthly_acquisitions=}, \\n{max_allowed_days_gap_per_orbit=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tile:\n",
    "    def __init__(self, row, col):\n",
    "        self.row = row\n",
    "        self.col = col\n",
    "        self.index = row,col\n",
    "        self.percent_valid_snow_pixels = self.get_percent_valid_snow_pixels()\n",
    "        self.geobox = self.get_geobox()\n",
    "        self.bbox_gdf = self.get_bbox_gdf()\n",
    "        self.start_time = None\n",
    "        self.total_time = None\n",
    "        self.s1_rtc_ds = None\n",
    "        self.s1_rtc_ds_dims = None\n",
    "        self.s1_rtc_masked_ds_dims = None\n",
    "        self.runoff_onsets = None\n",
    "        self.runoff_onsets_dims = None\n",
    "        self.tr_2015 = None\n",
    "        self.tr_2016 = None\n",
    "        self.tr_2017 = None\n",
    "        self.tr_2018 = None\n",
    "        self.tr_2019 = None\n",
    "        self.tr_2020 = None\n",
    "        self.tr_2021 = None\n",
    "        self.tr_2022 = None\n",
    "        self.tr_2023 = None\n",
    "        self.tr_2024 = None\n",
    "        self.error_messages = []\n",
    "        self.success = False\n",
    "\n",
    "    \n",
    "    def get_geobox(self):\n",
    "        return geobox_tiles[self.index]\n",
    "    \n",
    "    def get_bbox_gdf(self):\n",
    "        bbox = self.geobox.boundingbox\n",
    "        bbox_geometry = shapely.geometry.box(bbox.left, bbox.bottom, bbox.right, bbox.top)\n",
    "        bbox_gdf = gpd.GeoDataFrame(geometry=[bbox_geometry], crs=self.geobox.crs)\n",
    "        return bbox_gdf\n",
    "    \n",
    "    def get_percent_valid_snow_pixels(self):\n",
    "        return float(valid_tiles_gdf['percent_valid_snow_pixels'].loc[(valid_tiles_gdf['row'] == self.row) & (valid_tiles_gdf['col'] == self.col)].values[0])\n",
    "    \n",
    "    def get_info(self):\n",
    "        return f\"Processing Tile {self.index}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tiles_gdf = gpd.read_file('valid_tiles.geojson')\n",
    "valid_tiles_gdf = valid_tiles_gdf.sort_values(by='percent_valid_snow_pixels',ascending=False) \n",
    "\n",
    "global_geobox = odc.geo.geobox.GeoBox.from_bbox((bbox_left, bbox_bottom,\n",
    "   bbox_right, bbox_top),crs=\"epsg:4326\", resolution=resolution)\n",
    "\n",
    "geobox_tiles = odc.geo.geobox.GeoboxTiles(global_geobox,zarr_chunk_size)\n",
    "\n",
    "tiles = [Tile(row,col) for row,col in zip(valid_tiles_gdf.row,valid_tiles_gdf.col)]\n",
    "\n",
    "processed_tiles_df = pd.read_csv('tile_results.csv')\n",
    "processed_tiles_df = processed_tiles_df[processed_tiles_df['success'] == True]\n",
    "processed_tiles = set(zip(processed_tiles_df['row'], processed_tiles_df['col']))\n",
    "\n",
    "\n",
    "tiles = [tile for tile in tiles if (tile.row, tile.col) in processed_tiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_filesystem = adlfs.AzureBlobFileSystem(account_name=\"snowmelt\", credential=sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read global product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_store = azure_filesystem.get_mapper(\"snowmelt/snowmelt_runoff_onset/global.zarr\")\n",
    "global_ds = xr.open_zarr(global_store, consolidated=True,decode_coords='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip global product and reproject to UTM zone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinate_arrays(ds):\n",
    "    \"\"\"\n",
    "    Create additional arrays to store original lat/lon coordinates.\n",
    "    \"\"\"\n",
    "    lat, lon = np.meshgrid(ds.latitude, ds.longitude)\n",
    "    ds['original_lat'] = xr.DataArray(lat.T, dims=('latitude', 'longitude'))\n",
    "    ds['original_lon'] = xr.DataArray(lon.T, dims=('latitude', 'longitude'))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearrange data variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_water_year_dim_to_var(ds):\n",
    "    for year in ds.water_year.values:\n",
    "        ds[f'runoff_onset_WY{year}'] = ds['runoff_onset'].sel(water_year=year)\n",
    "\n",
    "    ds = ds.drop_vars('runoff_onset').drop_vars('water_year')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in variables: elevation, aspect, slope, tpi, snow class, esa worldcover, forest cover fraction... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_topography(tile,ds):\n",
    "    catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\",modifier=planetary_computer.sign_inplace)\n",
    "    search = catalog.search(collections=[f\"cop-dem-glo-30\"],intersects=tile.geobox.geographic_extent)\n",
    "    dem_da = odc.stac.load(items=search.items(),like=ds,chunks={},resampling='bilinear')['data'].squeeze()\n",
    "    dem_da = dem_da.rio.write_nodata(-32767,encoded=True).drop_vars('time').compute() # compute for xdem stuff\n",
    "\n",
    "    ds['dem'] = dem_da\n",
    "\n",
    "    # [xDEM](https://xdem.readthedocs.io/en/stable/index.html) to calculate slope and aspect and topographic position index\n",
    "\n",
    "    attributes = xdem.terrain.get_terrain_attribute(\n",
    "        ds['dem'],\n",
    "        resolution=ds['dem'].rio.resolution()[0],\n",
    "        attribute=[\"aspect\", \"slope\", \"topographic_position_index\"],\n",
    "    )\n",
    "\n",
    "    ds['aspect'] = xr.DataArray(attributes[0], dims=ds['dem'].dims, coords=ds['dem'].coords)\n",
    "    ds['slope'] = xr.DataArray(attributes[1], dims=ds['dem'].dims, coords=ds['dem'].coords)\n",
    "    # TPI? https://xdem.readthedocs.io/en/stable/gen_modules/xdem.DEM.topographic_position_index.html, https://tc.copernicus.org/articles/8/1989/2014/tc-8-1989-2014.pdf\n",
    "    # maybe incorrect radius...\n",
    "    ds['tpi'] = xr.DataArray(attributes[2], dims=ds['dem'].dims, coords=ds['dem'].coords)\n",
    "\n",
    "    # DAH?\n",
    "    # alpha_max = 202.5 #only in northern hemisphere at specific latitude?\n",
    "    # DAH_da = np.cos(np.deg2rad(alpha_max-aspect_da))*np.arctan(np.deg2rad(slope_da))\n",
    "\n",
    "    return ds\n",
    "\n",
    "def add_snow_class(tile,ds):\n",
    "\n",
    "    snow_classification = easysnowdata.remote_sensing.get_seasonal_snow_classification(tile.bbox_gdf)\n",
    "    ds['snow_classification'] = snow_classification.rio.reproject_match(ds['dem'],resampling=rasterio.enums.Resampling.mode)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def add_esa_worldcover(tile,ds):\n",
    "\n",
    "    esa_worldcover = easysnowdata.remote_sensing.get_esa_worldcover(tile.bbox_gdf)\n",
    "    esa_worldcover.rio.set_nodata(0,inplace=True)\n",
    "    ds['esa_worldcover'] = esa_worldcover.rio.reproject_match(ds['dem'],resampling=rasterio.enums.Resampling.mode)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def add_forest_cover(tile,ds):\n",
    "\n",
    "    forest_cover_fraction = easysnowdata.remote_sensing.get_forest_cover_fraction(tile.bbox_gdf)\n",
    "    ds['forest_cover_fraction'] = forest_cover_fraction.rio.reproject_match(ds['dem'],resampling=rasterio.enums.Resampling.bilinear)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalc median, std, nmad, trend, trend strength (use diff thresholds?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dataset with all variables to dataframe where each pixel location is a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_dataframe(tile,ds):\n",
    "    # only drop row values / a pixel if there are no runoff_onset_predictions for any of the years\n",
    "    # drop_subset = [f'runoff_onset_WY{water_year}' for water_year in water_years]\n",
    "\n",
    "    #df = ds.to_dataframe().reset_index().dropna(subset=drop_subset,how='all').drop_vars('spatial_ref', axis=1) use this if we want to keep pixels with runoff_onset_predictions for two or less years, for three or more use next line\n",
    "    df = ds.to_dataframe().reset_index().dropna(subset='runoff_onset_median').drop('spatial_ref', axis=1)\n",
    "\n",
    "    df['tile_row'] = tile.row\n",
    "    df['tile_col'] = tile.col\n",
    "    hemisphere = 'northern' if ds.rio.crs.to_epsg() < 32700 else 'southern'\n",
    "    df['hemisphere'] = hemisphere\n",
    "    # change these as we include/exclude new vars\n",
    "    df = df[[\"tile_row\",\"tile_col\",\"hemisphere\",\"original_lat\",\"original_lon\",\"runoff_onset_WY2015\",\"runoff_onset_WY2016\",\"runoff_onset_WY2017\",\"runoff_onset_WY2018\",\"runoff_onset_WY2019\",\"runoff_onset_WY2020\",\"runoff_onset_WY2021\",\"runoff_onset_WY2022\",\"runoff_onset_WY2023\",\"runoff_onset_WY2024\",\"runoff_onset_median\",\"runoff_onset_std\",\"dem\",\"aspect\",\"slope\",\"tpi\",\"snow_classification\",\"esa_worldcover\",\"forest_cover_fraction\"]]\n",
    "    \n",
    "    columns_to_round = [col for col in df.columns if col not in ['original_lat', 'original_lon', 'runoff_onset_std', 'hemisphere']]\n",
    "    df[columns_to_round] = df[columns_to_round].replace([np.inf, -np.inf, np.nan], -9999)\n",
    "    df[columns_to_round] = df[columns_to_round].round().astype(int)\n",
    "\n",
    "    df['original_lat'] = df['original_lat'].round(4)\n",
    "    df['original_lon'] = df['original_lon'].round(4)\n",
    "    df['runoff_onset_std'] = df['runoff_onset_std'].round(2)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif df[col].dtype == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_utm_datacube(tile, global_ds):\n",
    "    tile_ds = global_ds.rio.clip_box(*tile.get_geobox().boundingbox,crs='EPSG:4326')\n",
    "    tile_ds = add_coordinate_arrays(tile_ds)\n",
    "    utm_crs = tile_ds.rio.estimate_utm_crs()\n",
    "    tile_utm_ds = tile_ds.rio.reproject(utm_crs,resolution=80,resampling=rasterio.enums.Resampling.bilinear).persist()\n",
    "    tile_utm_ds = convert_water_year_dim_to_var(tile_utm_ds)\n",
    "    tile_utm_ds = add_topography(tile,tile_utm_ds)\n",
    "    tile_utm_ds = add_snow_class(tile,tile_utm_ds)\n",
    "    tile_utm_ds = add_esa_worldcover(tile,tile_utm_ds)\n",
    "    tile_utm_ds = add_forest_cover(tile,tile_utm_ds)\n",
    "    return tile_utm_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_analysis_parquet(tile, filename, filesystem, global_ds):\n",
    "    print(f\"Processing {filename}\")\n",
    "    try:\n",
    "        tile_utm_ds = create_utm_datacube(tile, global_ds)\n",
    "        tile_utm_df = dataset_to_dataframe(tile, tile_utm_ds)\n",
    "        tile_utm_df.to_parquet(f\"snowmelt/analysis/tiles/{filename}\",filesystem=filesystem)\n",
    "        print(f\"Saved {filename}\")\n",
    "        return filename, True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        return filename, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = tiles[2]\n",
    "tiles[2].index\n",
    "tile.geobox.explore(tiles='EsriWorldImagery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_utm_ds = create_utm_datacube(tile, global_ds)\n",
    "tile_utm_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_utm_df = dataset_to_dataframe(tile,tile_utm_ds)\n",
    "tile_utm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(idle_timeout=\"10 minutes\",\n",
    "                         n_workers=5,\n",
    "                         worker_memory=\"64 GB\",\n",
    "                         worker_cpu=8,\n",
    "                         scheduler_memory=\"32 GB\",\n",
    "                         spot_policy=\"spot\",\n",
    "                         environ={\"GDAL_DISABLE_READDIR_ON_OPEN\": \"EMPTY_DIR\"},\n",
    "                         workspace=\"azure\",\n",
    "                         )\n",
    "\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    existing_filenames = [pathlib.Path(path).name for path in azure_filesystem.ls('snowmelt/analysis/tiles/')]\n",
    "except:\n",
    "    existing_filenames = []\n",
    "        \n",
    "futures = []\n",
    "\n",
    "for tile in tqdm.tqdm(tiles,total=len(tiles)):\n",
    "\n",
    "    filename = f'tile_{tile.row:03d}_{tile.col:03d}.parquet'\n",
    "\n",
    "    if filename in existing_filenames:\n",
    "        print(f'{filename} already exists, skipping...')\n",
    "        continue\n",
    "\n",
    "    future = client.submit(create_and_save_analysis_parquet, tile, filename, azure_filesystem, global_ds, retries=1)\n",
    "    futures.append(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for future, result in dask.distributed.as_completed(futures, with_results=True):\n",
    "    print(f\"{result[0]} : {'SUCCESS' if result[1] == True else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = azure_filesystem.ls('snowmelt/analysis/tiles/')\n",
    "parquet_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view_tile(Tile(13,126)) very dense norway\n",
    "#view_tile(Tile(1,133)) svalbard\n",
    "#view_tile(Tile(88,72)) SA\n",
    "#Tile(88,72).get_geobox().boundingbox\n",
    "#test_ds = global_ds.rio.clip_box(-75,-51,-72,-48,crs='EPSG:4326') area surrounding SA tile, other tiles should be adjacenent\n",
    "#f,ax=plt.subplots(2,1,figsize=(10,10))\n",
    "#test_ds['runoff_onset_median'].plot.imshow(ax=ax[0],vmin=0,vmax=365)\n",
    "#test_ds['runoff_onset_std'].plot.imshow(ax=ax[1],cmap='Reds')\n",
    "#test_ds['runoff_onset'].plot.imshow(col='water_year',col_wrap=3,vmin=0,vmax=365)\n",
    "\n",
    "\n",
    "# def view_tile(tile: Tile):\n",
    "\n",
    "\n",
    "#     test_ds = global_ds.rio.clip_box(*tile.get_geobox().boundingbox,crs='EPSG:4326')\n",
    "\n",
    "#     f,ax=plt.subplots(2,1,figsize=(10,10))\n",
    "#     test_ds['runoff_onset_median'].plot.imshow(ax=ax[0],vmin=0,vmax=365)\n",
    "\n",
    "#     test_ds['runoff_onset_std'].plot.imshow(ax=ax[1],cmap='Reds')\n",
    "\n",
    "#     test_ds['runoff_onset'].plot.imshow(col='water_year',col_wrap=3,vmin=0,vmax=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile_ds = global_ds.rio.clip_box(*tile.get_geobox().boundingbox,crs='EPSG:4326').compute()\n",
    "# tile_ds\n",
    "\n",
    "# tile_ds = add_coordinate_arrays(tile_ds)\n",
    "# tile_ds\n",
    "# utm_crs = tile_ds.rio.estimate_utm_crs()\n",
    "# tile_utm_ds = tile_ds.rio.reproject(utm_crs,resolution=80,resampling=rasterio.enums.Resampling.bilinear)\n",
    "# tile_utm_ds\n",
    "\n",
    "# tile_utm_ds['runoff_onset'].plot.imshow(col='water_year',col_wrap=3,robust=True)\n",
    "\n",
    "# f,axs = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "# tile_utm_ds['runoff_onset_median'].plot.imshow(ax=axs[0],robust=True)\n",
    "# tile_utm_ds['runoff_onset_std'].plot.imshow(ax=axs[1],robust=True,cmap='Reds')\n",
    "\n",
    "# for ax in axs:\n",
    "#     ax.set_aspect('equal')\n",
    "\n",
    "# f,axs=plt.subplots(1,2,figsize=(10,5))\n",
    "# tile_utm_ds['original_lat'].plot.imshow(ax=axs[0])\n",
    "# tile_utm_ds['original_lon'].plot.imshow(ax=axs[1])\n",
    "# axs[0].set_title('original_lat')\n",
    "# axs[1].set_title('original_lon')\n",
    "\n",
    "# for ax in axs:\n",
    "#     ax.set_aspect('equal')\n",
    "\n",
    "# tile_utm_ds = convert_water_year_dim_to_var(tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_ds = add_topography(tile,tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_ds = add_snow_class(tile,tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_ds = add_esa_worldcover(tile,tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_ds = add_forest_cover(tile,tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_df = dataset_to_dataframe(tile_utm_ds,utm_crs,water_years)\n",
    "# tile_utm_df\n",
    "# tile_results_df = pd.read_csv(f'results/tile_{tile.row:03d}_{tile.col:03d}.csv')\n",
    "\n",
    "\n",
    "# var_list = ['runoff_onset_median','runoff_onset_std','aspect','slope','tpi','snow_classification','esa_worldcover','forest_cover_fraction']\n",
    "# tile_utm_ds.hvplot.image(z=var_list,tiles=\"EsriImagery\",crs=tile_utm_ds.rio.crs,width=500,height=500) # hover_cols=var_list\n",
    "\n",
    "\n",
    "# num_vars = len(tile_utm_ds.data_vars)\n",
    "\n",
    "# # Calculate the number of rows and columns for the subplots\n",
    "# num_cols = 3  # You can adjust this\n",
    "# num_rows = (num_vars + num_cols - 1) // num_cols\n",
    "\n",
    "# # Create a figure with subplots\n",
    "# fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5*num_rows))\n",
    "# axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "# # Loop through each variable and plot\n",
    "# for i, (var_name, da) in enumerate(tile_utm_ds.data_vars.items()):\n",
    "#     ax = axes[i]\n",
    "#     da.plot(ax=ax)\n",
    "#     ax.set_title(var_name)\n",
    "\n",
    "# # Remove any unused subplots\n",
    "# for j in range(i+1, len(axes)):\n",
    "#     fig.delaxes(axes[j])\n",
    "\n",
    "# # f,axs=plt.subplots(2,2,figsize=(10,10),sharex=True,sharey=True)\n",
    "\n",
    "\n",
    "# # tile_utm_ds['dem'].plot.imshow(ax=axs[0,0])\n",
    "# # tile_utm_ds['aspect'].plot.imshow(ax=axs[0,1],cmap='twilight')\n",
    "# # tile_utm_ds['slope'].plot.imshow(ax=axs[1,0],cmap='Reds')\n",
    "# # tile_utm_ds['tpi'].plot.imshow(ax=axs[1,1],cmap='Purples')\n",
    "\n",
    "# # titles = ['DEM','Aspect','Slope','TPI']\n",
    "\n",
    "# # for ax,title in zip(axs.flatten(),titles):\n",
    "# #     ax.set_aspect('equal')\n",
    "# #     ax.set_title(title)\n",
    "\n",
    "# # f.tight_layout()\n",
    "# # \n",
    "# # #hvplot.explorer(tile_utm_ds, x='x', y='y')\n",
    "# # \n",
    "# # #hvplot.help(\"image\")\n",
    "\n",
    "# tile_utm_df.to_csv(f'results/tile_{tile.row:03d}_{tile.col:03d}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sar_snowmelt_timing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
