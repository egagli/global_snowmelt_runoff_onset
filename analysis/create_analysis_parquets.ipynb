{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create parquet files for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import xarray as xr\n",
    "import pathlib\n",
    "import dask\n",
    "import dask.distributed\n",
    "import coiled\n",
    "from global_snowmelt_runoff_onset.config import Config\n",
    "from global_snowmelt_runoff_onset.analysis import create_and_save_analysis_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config('../config/global_config.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ds = xr.open_zarr(config.global_runoff_store, consolidated=True,decode_coords='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.valid_tiles_gdf.explore(column='success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(idle_timeout=\"10 minutes\",\n",
    "                         n_workers=40,\n",
    "                         worker_memory=\"64 GB\",\n",
    "                         worker_cpu=8,\n",
    "                         scheduler_memory=\"64 GB\",\n",
    "                         spot_policy=\"spot\",\n",
    "                         environ={\"GDAL_DISABLE_READDIR_ON_OPEN\": \"EMPTY_DIR\"},\n",
    "                         workspace=\"uwtacolab\", #\"azure\"\n",
    "                         )\n",
    "\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = config.get_list_of_tiles(which='processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    existing_filenames = [pathlib.Path(path).name for path in config.azure_blob_fs.ls('snowmelt/analysis/tiles/')]\n",
    "except:\n",
    "    existing_filenames = []\n",
    "        \n",
    "\n",
    "tiles = [tile for tile in tiles if f'tile_{tile.row:03d}_{tile.col:03d}.parquet' not in existing_filenames]\n",
    "filenames = [f'tile_{tile.row:03d}_{tile.col:03d}.parquet' for tile in tiles if f'tile_{tile.row:03d}_{tile.col:03d}.parquet' not in existing_filenames]\n",
    "\n",
    "futures = []\n",
    "\n",
    "for tile,filename in tqdm.tqdm(zip(tiles,filenames),total=len(filenames)):\n",
    "    future = client.submit(create_and_save_analysis_parquet, tile, filename, config.azure_blob_fs, global_ds, config.ee_credentials, retries=3)\n",
    "    futures.append(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for future,result in dask.distributed.as_completed(futures, with_results=True):\n",
    "    if result[1] == True:\n",
    "        print(f\"Successfully processed tile {result[0]}\")\n",
    "    if result[1] == False:\n",
    "        print(f\"Failed for tile {result[0]} with error: {result[2]} and traceback: {result[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = config.azure_blob_fs.ls('snowmelt/analysis/tiles/')\n",
    "parquet_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parquet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(existing_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile = config.get_tile(14,27)\n",
    "# tile.geobox.explore(tiles='EsriWorldImagery')\n",
    "\n",
    "# tile_utm_ds = create_utm_datacube(tile, global_ds)\n",
    "# tile_utm_ds\n",
    "\n",
    "\n",
    "# # Get the number of variables\n",
    "# n_vars = len(tile_utm_ds.data_vars)\n",
    "\n",
    "# # Calculate the number of rows and columns for the subplots\n",
    "# n_cols = 4  # You can adjust this number as needed\n",
    "# n_rows = (n_vars + n_cols - 1) // n_cols\n",
    "\n",
    "# # Create the figure and subplots\n",
    "# f,axs = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "# axs = axs.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "# # Plot each variable\n",
    "# for i, (var_name, da) in enumerate(tile_utm_ds.data_vars.items()):\n",
    "#     da.plot(ax=axs[i], cmap='viridis')\n",
    "#     axs[i].set_title(var_name)\n",
    "\n",
    "# # Remove any unused subplots\n",
    "# for j in range(i+1, len(axs)):\n",
    "#     f.delaxes(axs[j])\n",
    "\n",
    "# f.tight_layout()\n",
    "\n",
    "# tile_utm_df = dataset_to_dataframe(tile,tile_utm_ds)\n",
    "# tile_utm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view_tile(Tile(13,126)) very dense norway\n",
    "#view_tile(Tile(1,133)) svalbard\n",
    "#view_tile(Tile(88,72)) SA\n",
    "#Tile(88,72).get_geobox().boundingbox\n",
    "#test_ds = global_ds.rio.clip_box(-75,-51,-72,-48,crs='EPSG:4326') area surrounding SA tile, other tiles should be adjacenent\n",
    "#f,ax=plt.subplots(2,1,figsize=(10,10))\n",
    "#test_ds['runoff_onset_median'].plot.imshow(ax=ax[0],vmin=0,vmax=365)\n",
    "#test_ds['runoff_onset_std'].plot.imshow(ax=ax[1],cmap='Reds')\n",
    "#test_ds['runoff_onset'].plot.imshow(col='water_year',col_wrap=3,vmin=0,vmax=365)\n",
    "\n",
    "\n",
    "# def view_tile(tile: Tile):\n",
    "\n",
    "\n",
    "#     test_ds = global_ds.rio.clip_box(*tile.get_geobox().boundingbox,crs='EPSG:4326')\n",
    "\n",
    "#     f,ax=plt.subplots(2,1,figsize=(10,10))\n",
    "#     test_ds['runoff_onset_median'].plot.imshow(ax=ax[0],vmin=0,vmax=365)\n",
    "\n",
    "#     test_ds['runoff_onset_std'].plot.imshow(ax=ax[1],cmap='Reds')\n",
    "\n",
    "#     test_ds['runoff_onset'].plot.imshow(col='water_year',col_wrap=3,vmin=0,vmax=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile_ds = global_ds.rio.clip_box(*tile.get_geobox().boundingbox,crs='EPSG:4326').compute()\n",
    "# tile_ds\n",
    "\n",
    "# tile_ds = add_coordinate_arrays(tile_ds)\n",
    "# tile_ds\n",
    "# utm_crs = tile_ds.rio.estimate_utm_crs()\n",
    "# tile_utm_ds = tile_ds.rio.reproject(utm_crs,resolution=80,resampling=rasterio.enums.Resampling.bilinear)\n",
    "# tile_utm_ds\n",
    "\n",
    "# tile_utm_ds['runoff_onset'].plot.imshow(col='water_year',col_wrap=3,robust=True)\n",
    "\n",
    "# f,axs = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "# tile_utm_ds['runoff_onset_median'].plot.imshow(ax=axs[0],robust=True)\n",
    "# tile_utm_ds['runoff_onset_std'].plot.imshow(ax=axs[1],robust=True,cmap='Reds')\n",
    "\n",
    "# for ax in axs:\n",
    "#     ax.set_aspect('equal')\n",
    "\n",
    "# f,axs=plt.subplots(1,2,figsize=(10,5))\n",
    "# tile_utm_ds['original_lat'].plot.imshow(ax=axs[0])\n",
    "# tile_utm_ds['original_lon'].plot.imshow(ax=axs[1])\n",
    "# axs[0].set_title('original_lat')\n",
    "# axs[1].set_title('original_lon')\n",
    "\n",
    "# for ax in axs:\n",
    "#     ax.set_aspect('equal')\n",
    "\n",
    "# tile_utm_ds = convert_water_year_dim_to_var(tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_ds = add_topography(tile,tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_ds = add_snow_class(tile,tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_ds = add_esa_worldcover(tile,tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_ds = add_forest_cover(tile,tile_utm_ds)\n",
    "# tile_utm_ds\n",
    "# tile_utm_df = dataset_to_dataframe(tile_utm_ds,utm_crs,water_years)\n",
    "# tile_utm_df\n",
    "# tile_results_df = pd.read_csv(f'results/tile_{tile.row:03d}_{tile.col:03d}.csv')\n",
    "\n",
    "\n",
    "# var_list = ['runoff_onset_median','runoff_onset_std','aspect','slope','tpi','snow_classification','esa_worldcover','forest_cover_fraction']\n",
    "# tile_utm_ds.hvplot.image(z=var_list,tiles=\"EsriImagery\",crs=tile_utm_ds.rio.crs,width=500,height=500) # hover_cols=var_list\n",
    "\n",
    "\n",
    "# num_vars = len(tile_utm_ds.data_vars)\n",
    "\n",
    "# # Calculate the number of rows and columns for the subplots\n",
    "# num_cols = 3  # You can adjust this\n",
    "# num_rows = (num_vars + num_cols - 1) // num_cols\n",
    "\n",
    "# # Create a figure with subplots\n",
    "# fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5*num_rows))\n",
    "# axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "# # Loop through each variable and plot\n",
    "# for i, (var_name, da) in enumerate(tile_utm_ds.data_vars.items()):\n",
    "#     ax = axes[i]\n",
    "#     da.plot(ax=ax)\n",
    "#     ax.set_title(var_name)\n",
    "\n",
    "# # Remove any unused subplots\n",
    "# for j in range(i+1, len(axes)):\n",
    "#     fig.delaxes(axes[j])\n",
    "\n",
    "# # f,axs=plt.subplots(2,2,figsize=(10,10),sharex=True,sharey=True)\n",
    "\n",
    "\n",
    "# # tile_utm_ds['dem'].plot.imshow(ax=axs[0,0])\n",
    "# # tile_utm_ds['aspect'].plot.imshow(ax=axs[0,1],cmap='twilight')\n",
    "# # tile_utm_ds['slope'].plot.imshow(ax=axs[1,0],cmap='Reds')\n",
    "# # tile_utm_ds['tpi'].plot.imshow(ax=axs[1,1],cmap='Purples')\n",
    "\n",
    "# # titles = ['DEM','Aspect','Slope','TPI']\n",
    "\n",
    "# # for ax,title in zip(axs.flatten(),titles):\n",
    "# #     ax.set_aspect('equal')\n",
    "# #     ax.set_title(title)\n",
    "\n",
    "# # f.tight_layout()\n",
    "# # \n",
    "# # #hvplot.explorer(tile_utm_ds, x='x', y='y')\n",
    "# # \n",
    "# # #hvplot.help(\"image\")\n",
    "\n",
    "# tile_utm_df.to_csv(f'results/tile_{tile.row:03d}_{tile.col:03d}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_snowmelt_runoff_onset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
